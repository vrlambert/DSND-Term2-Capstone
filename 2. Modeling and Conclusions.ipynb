{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project - Part 2\n",
    "\n",
    "If you didn't read the first part, you should! This one picks up where it leaves off and starts using the full 12GB dataset. We will first verify our assumptions from the first notebook, then run the feature engineering script and train a few basic models to see how they perform. First we'll create the spark session and import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111ab6f67a824b67bf4fa9293f4aaa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>14</td><td>application_1548012558125_0015</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-39-69.us-east-2.compute.internal:20888/proxy/application_1548012558125_0015/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-41-133.us-east-2.compute.internal:8042/node/containerlogs/container_1548012558125_0015_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# Starter code\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e456424247cb498b8d63b698e409379f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "import pyspark.sql.types as st\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95e1d4bfa44a84b94fbc4843460e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next read in the full dataset from the public s3 bucket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf4a18cad09406bbc6845fbf8b31643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in full sparkify dataset\n",
    "event_data = \"s3n://dsnd-sparkify/sparkify_event_data.json\"\n",
    "df_raw = spark.read.json(event_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next check the head and the schema to see if everything looks similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d5b29895e344e2937f714c63ef5fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist=u'Popol Vuh', auth=u'Logged In', firstName=u'Shlok', gender=u'M', itemInSession=278, lastName=u'Johnson', length=524.32934, level=u'paid', location=u'Dallas-Fort Worth-Arlington, TX', method=u'PUT', page=u'NextSong', registration=1533734541000, sessionId=22683, song=u'Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent=u'\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId=u'1749042')"
     ]
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79befdccc63b482ea4730c77856270d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26259199"
     ]
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy cow, that's a big increase from the subset. Although we expected it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e929c88ce545d9b214dd23ec5f848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n",
      "| artist|auth|firstName|gender|itemInSession|lastName| length|level|location|method|page|registration|sessionId|   song|status| ts|userAgent|userId|\n",
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n",
      "|5408927|   0|   778479|778479|            0|  778479|5408927|    0|  778479|     0|   0|      778479|        0|5408927|     0|  0|   778479|     0|\n",
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+"
     ]
    }
   ],
   "source": [
    "df_raw.select([sf.count(sf.when(sf.isnull(c), c)).alias(c) for c in df_raw.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at some missing values, it looks like the pattern is the same as the subset. Let's just check for the `\"\"` user like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a84ed33deb45d0892cf1d733cfc654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    }
   ],
   "source": [
    "df_raw.filter(df_raw.userId == \"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, that's weird, there aren't any. Let's see what user shows up then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| userId|\n",
      "+-------+\n",
      "|1261737|\n",
      "+-------+"
     ]
    }
   ],
   "source": [
    "df_raw.where(sf.isnull(df_raw.registration)).select('userId').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a1f7713b6a4f55bebfc7a045b72a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| userId|\n",
      "+-------+\n",
      "|1261737|\n",
      "+-------+"
     ]
    }
   ],
   "source": [
    "df_raw.where(sf.isnull(df_raw.gender)).select('userId').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, looks like `1261737` is the null user instead of empty string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778479"
     ]
    }
   ],
   "source": [
    "df.filter(df.userId==1261737).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd43674bc8d54c0ca4b54aec264a3597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sessionId|\n",
      "+---------+\n",
      "|    23116|\n",
      "|    33760|\n",
      "|    30428|\n",
      "|    35323|\n",
      "|    35484|\n",
      "|    13248|\n",
      "|    38878|\n",
      "|    38543|\n",
      "|    27919|\n",
      "|    48763|\n",
      "|    52001|\n",
      "|    17048|\n",
      "|    52051|\n",
      "|    48899|\n",
      "|    47492|\n",
      "|    49983|\n",
      "|    52611|\n",
      "|    50049|\n",
      "|    50329|\n",
      "|    50287|\n",
      "+---------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_raw.where(sf.isnull(df_raw.registration)).select('sessionId').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it looks like sessions aren't specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "We will use the same functions from the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac19b0a81b234f6e9456de43cfa9523f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_ms(x):\n",
    "    \"\"\"Converts given ns to ms\"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "    \n",
    "    return x//1000\n",
    "\n",
    "convert_ms_udf = sf.udf(convert_ms, st.LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278cbaed00af4fa6b7c2c48577a3f632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_df(df_raw):\n",
    "    \"\"\"\n",
    "    Takes in a raw events dataframe, makes a few extra columns and cleans it.\n",
    "    \"\"\"\n",
    "    df = df_raw.filter(df_raw.userId != 1261737)\n",
    "    \n",
    "    df = df.withColumn('timestamp', convert_ms_udf(df.ts).cast('timestamp'))\n",
    "    df = df.withColumn('registration_ts', convert_ms_udf(df.registration).cast('timestamp'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9300f4537e43208c871d7f25e38d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# after reading in the df just running this cell catches up with the exploration\n",
    "df = clean_df(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb683279f0b8469a947b148b36574ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n",
      "| artist|auth|firstName|gender|itemInSession|lastName| length|level|location|method|page|registration|sessionId|   song|status| ts|userAgent|userId|\n",
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+\n",
      "|4630448|   0|        0|     0|            0|       0|4630448|    0|       0|     0|   0|           0|        0|4630448|     0|  0|        0|     0|\n",
      "+-------+----+---------+------+-------------+--------+-------+-----+--------+------+----+------------+---------+-------+------+---+---------+------+"
     ]
    }
   ],
   "source": [
    "df.select([sf.count(sf.when(sf.isnull(c), c)).alias(c) for c in df_raw.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check out the number of users and sessions in the full data, turns out there are still a sizeable number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a5b74a9e5c48aca2a4cd67a05b7919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------------+\n",
      "|count(DISTINCT userId)|count(DISTINCT sessionId)|\n",
      "+----------------------+-------------------------+\n",
      "|                 22277|                   223096|\n",
      "+----------------------+-------------------------+"
     ]
    }
   ],
   "source": [
    "df.agg(sf.countDistinct('userId'), sf.countDistinct('sessionId')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also turns out the timestamp range is similar to the other data, although the registration range is longer as we would expect from a larger user group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d421b090c44f43a2950c960a5f6f6aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|     min(timestamp)|     max(timestamp)|\n",
      "+-------------------+-------------------+\n",
      "|2018-10-01 00:00:01|2018-12-01 00:00:02|\n",
      "+-------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "df.agg(sf.min('timestamp'), sf.max('timestamp')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a30ec498e694b439eb207c99ed7bd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|min(registration_ts)|max(registration_ts)|\n",
      "+--------------------+--------------------+\n",
      "| 2017-10-14 22:05:25| 2018-12-03 07:23:42|\n",
      "+--------------------+--------------------+"
     ]
    }
   ],
   "source": [
    "df.agg(sf.min('registration_ts'), sf.max('registration_ts')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting the that last registration is after the end of the events data - seems like a possible error but probably won't be a big deal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081585018f474cf2b4e7516679b05874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_df(df):\n",
    "    \"\"\"Takes in a cleaned event dataframe and returns a feature dataframe\"\"\"\n",
    "    \n",
    "    # Column names for the vector\n",
    "    vector_cols = []\n",
    "    \n",
    "    # Get session counts\n",
    "    session_counts = df.groupby('userId').agg(sf.countDistinct('sessionId').alias('session_count'))\n",
    "    vector_cols.append('session_count')\n",
    "    \n",
    "    # Get pages and ignore events\n",
    "    pages = df.select('page').distinct().sort('page')\n",
    "    pages_list = [r.page for r in pages.collect()]\n",
    "    drop_events = ['Cancel']\n",
    "    \n",
    "    # Get event counts\n",
    "    feat_df = df.groupby('userId').pivot('page', pages_list).count()\n",
    "    feat_df = feat_df.withColumnRenamed('Cancellation Confirmation', 'label')\n",
    "    feat_df = feat_df.drop(*drop_events).fillna(0)\n",
    "    \n",
    "    feat_df = feat_df.join(session_counts, on='userId')\n",
    "    \n",
    "    # Normalize by session counts\n",
    "    ignore_cols = {'userId', 'session_count', 'label'}\n",
    "    remaining_cols = sorted(list(set(feat_df.columns) - ignore_cols))\n",
    "    for column in remaining_cols:\n",
    "        feat_df = feat_df.withColumn(column, sf.col(column) / feat_df.session_count)\n",
    "    vector_cols.extend(remaining_cols)\n",
    "    \n",
    "    # Get account ages\n",
    "    max_timestamp = df.agg(sf.max('timestamp')).first()[0]\n",
    "    account_ages = df.select('userId', \n",
    "                             sf.datediff(sf.lit(max_timestamp), df.registration_ts).alias('account_age')).distinct()\n",
    "    \n",
    "    vector_cols.append('account_age')\n",
    "    feat_df = feat_df.join(account_ages, on='userId')\n",
    "    \n",
    "    # Get weekly song counts\n",
    "    week_counts = df.where(df.page=='NextSong') \\\n",
    "                .groupby('userId', sf.date_trunc('week', 'timestamp').cast('date').alias('week')).count() \\\n",
    "                .groupby('userId').pivot('week').sum().fillna(0)\n",
    "    \n",
    "    vector_cols.extend(week_counts.columns[1:])\n",
    "    feat_df = feat_df.join(week_counts, on='userId')\n",
    "    \n",
    "    # Get genders\n",
    "    genders = df.select('userId', sf.when(sf.col('gender')=='F', 0).otherwise(1).alias('genders')).distinct()\n",
    "    \n",
    "    vector_cols.append('genders')\n",
    "    feat_df = feat_df.join(genders, on='userId')\n",
    "    \n",
    "    # Assemble the vector\n",
    "    assembler = VectorAssembler(inputCols=vector_cols, outputCol='features')\n",
    "    \n",
    "    return assembler.transform(feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the feature dataframe and make sure everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = get_feature_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da47fa2b945475fa4e276ad6c219a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- About: double (nullable = true)\n",
      " |-- Add Friend: double (nullable = true)\n",
      " |-- Add to Playlist: double (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      " |-- Downgrade: double (nullable = true)\n",
      " |-- Error: double (nullable = true)\n",
      " |-- Help: double (nullable = true)\n",
      " |-- Home: double (nullable = true)\n",
      " |-- Logout: double (nullable = true)\n",
      " |-- NextSong: double (nullable = true)\n",
      " |-- Roll Advert: double (nullable = true)\n",
      " |-- Save Settings: double (nullable = true)\n",
      " |-- Settings: double (nullable = true)\n",
      " |-- Submit Downgrade: double (nullable = true)\n",
      " |-- Submit Upgrade: double (nullable = true)\n",
      " |-- Thumbs Down: double (nullable = true)\n",
      " |-- Thumbs Up: double (nullable = true)\n",
      " |-- Upgrade: double (nullable = true)\n",
      " |-- session_count: long (nullable = false)\n",
      " |-- account_age: integer (nullable = true)\n",
      " |-- 2018-10-01: long (nullable = true)\n",
      " |-- 2018-10-08: long (nullable = true)\n",
      " |-- 2018-10-15: long (nullable = true)\n",
      " |-- 2018-10-22: long (nullable = true)\n",
      " |-- 2018-10-29: long (nullable = true)\n",
      " |-- 2018-11-05: long (nullable = true)\n",
      " |-- 2018-11-12: long (nullable = true)\n",
      " |-- 2018-11-19: long (nullable = true)\n",
      " |-- 2018-11-26: long (nullable = true)\n",
      " |-- genders: integer (nullable = false)\n",
      " |-- features: vector (nullable = true)"
     ]
    }
   ],
   "source": [
    "feature_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0833acb024d7473db375576a8885ffcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[userId: string, About: double, Add Friend: double, Add to Playlist: double, label: bigint, Downgrade: double, Error: double, Help: double, Home: double, Logout: double, NextSong: double, Roll Advert: double, Save Settings: double, Settings: double, Submit Downgrade: double, Submit Upgrade: double, Thumbs Down: double, Thumbs Up: double, Upgrade: double, session_count: bigint, account_age: int, 2018-10-01: bigint, 2018-10-08: bigint, 2018-10-15: bigint, 2018-10-22: bigint, 2018-10-29: bigint, 2018-11-05: bigint, 2018-11-12: bigint, 2018-11-19: bigint, 2018-11-26: bigint, genders: int, features: vector]"
     ]
    }
   ],
   "source": [
    "feature_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf22ad2f397041a188401a312f4ce40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(userId=u'1000280', About=0.0, Add Friend=0.6363636363636364, Add to Playlist=1.1363636363636365, label=1, Downgrade=0.13636363636363635, Error=0.13636363636363635, Help=0.36363636363636365, Home=2.0, Logout=0.6818181818181818, NextSong=46.45454545454545, Roll Advert=3.3636363636363638, Save Settings=0.045454545454545456, Settings=0.4090909090909091, Submit Downgrade=0.045454545454545456, Submit Upgrade=0.045454545454545456, Thumbs Down=1.5, Thumbs Up=2.409090909090909, Upgrade=0.4090909090909091, session_count=22, account_age=95, 2018-10-01=308, 2018-10-08=34, 2018-10-15=291, 2018-10-22=57, 2018-10-29=187, 2018-11-05=38, 2018-11-12=107, 2018-11-19=0, 2018-11-26=0, genders=1, features=DenseVector([22.0, 0.0, 0.6364, 1.1364, 0.1364, 0.1364, 0.3636, 2.0, 0.6818, 46.4545, 3.3636, 0.0455, 0.4091, 0.0455, 0.0455, 1.5, 2.4091, 0.4091, 95.0, 308.0, 34.0, 291.0, 57.0, 187.0, 38.0, 107.0, 0.0, 0.0, 1.0]))]"
     ]
    }
   ],
   "source": [
    "feature_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's check the number of users in each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8779c9c6f7d456a845063da2c67f3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|17259|\n",
      "|    1| 5002|\n",
      "+-----+-----+"
     ]
    }
   ],
   "source": [
    "feature_df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a decent balance after all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "First we'll split the data into a test and train sets, then we'll run through a few different models to see which is the most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f5cd77bc3e4ff396ed68b5acb6b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = feature_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to start with a logistic regression just to get a feel for some code, but then I'm going to move on to decision trees. Luckily, decision trees don't require feature scaling so it should be ok in the current state of the feature vector. First we will create the model, then build a parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb76d2edaa234b68a7a72e7b35ec63b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr =  LogisticRegression(maxIter=10, regParam=0.0, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7334826fab7b4e3b9ddf06fbe530cca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam,[0.0, 0.1]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's really advantageous to use the `CrossValidator` here because it means we can try out a variety of parameters and automatically select the best ones using a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c6d2b118484f829452332bcc64ce1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, train on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0bdb6fe4724b65864a31465bbfe8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_lr = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average metrics here correspond to area under ROC curve, which is a great metric for evaluating binary classification. Mostly I just print it here to make sure it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708d66cd38f949a2be4b982a02dcadc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8724927340700368, 0.8581148562376506]"
     ]
    }
   ],
   "source": [
    "train_lr.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, generate the results vector from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fd8d4a858d467e997ab67ae39e4338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_lr = train_lr.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define this useful function to print out some evaluation metrics from the results vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7248e4d604f34f6d9c0d6c0aab32960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_metrics(res):\n",
    "    \"\"\"Given a results vector returns accuracy and f1-score\"\"\"\n",
    "    total = res.count()\n",
    "    \n",
    "    tp = res.where((res.label==1) & (res.prediction==1)).count()\n",
    "    tn = res.where((res.label==0) & (res.prediction==0)).count()\n",
    "    \n",
    "    fp = res.where((res.label==0) & (res.prediction==1)).count()\n",
    "    fn = res.where((res.label==1) & (res.prediction==0)).count()\n",
    "        \n",
    "    accuracy = (1.0*tp + tn) / total\n",
    "    precision = 1.0*tp / (tp + fp)\n",
    "    recall = 1.0*tp / (tp + fn)\n",
    "    f1 = 2.0 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    print('Accuracy: ', round(accuracy, 2))\n",
    "    print('Precision: ', round(precision, 2))\n",
    "    print('Recall: ', round(recall, 2))\n",
    "    print('F1-Score: ', round(f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54db45d215574086aae2f6ef6d30f6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.85)\n",
      "('Precision: ', 0.78)\n",
      "('Recall: ', 0.46)\n",
      "('F1-Score: ', 0.58)"
     ]
    }
   ],
   "source": [
    "get_metrics(results_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the logisitic regression model actually performed fairly well! Not great but not terribly. Next we can move on to a basic decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464657b5715a4c459347b5d46cfe999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1bb35dec5f4011bbb225cd2460354f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(dt.maxDepth, [3, 5, 7]) \\\n",
    "                .addGrid(dt.minInstancesPerNode, [1, 3, 5]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215fcf9d18704714a183ea518c6c5c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_crossval = CrossValidator(estimator = dt,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator = BinaryClassificationEvaluator(),\n",
    "                             numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = dt_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b3b4cdfc5b48dd921227f5533bf572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8273880001860734, 0.8273880001860734, 0.8273880001860734, 0.8291456054470742, 0.8266169100477181, 0.7852490410095025, 0.803507766675378, 0.7921751221437958, 0.7865720684865891]"
     ]
    }
   ],
   "source": [
    "model_dt.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a6fb3157c14d2bbba74fadabe340fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dt = model_dt.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61c0a07c8d342adb761c81b2c6ecee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.9)\n",
      "('Precision: ', 0.8)\n",
      "('Recall: ', 0.71)\n",
      "('F1-Score: ', 0.76)"
     ]
    }
   ],
   "source": [
    "get_metrics(results_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the decision tree actually performed quite well! 0.76 f1-score is respectable, and 0.9 accuracy is great. Next let's see how Random Forests does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6db1e49ce2442bf8b01536a4af382aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec150cdeb44498b9afdd2d39149732f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(rf.maxDepth, [3, 5, 7]) \\\n",
    "                .addGrid(rf.minInstancesPerNode, [1, 3, 5]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41fb442154446e4a3b5a09df1bc93fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_crossval = CrossValidator(estimator = rf,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator = BinaryClassificationEvaluator(),\n",
    "                             numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = rf_crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe211300c81417f8e7bde81090ea0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.904789115085872, 0.90478895477181, 0.9047911787971201, 0.9169346891040968, 0.9173023225091668, 0.916875486452861, 0.9254453792776469, 0.9257542682113924, 0.9249778436312617]"
     ]
    }
   ],
   "source": [
    "model_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9163f283f8d413d8f789958c2b04a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_rf = model_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c3006514de4e5db7c2a7c8e502f03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.91)\n",
      "('Precision: ', 0.91)\n",
      "('Recall: ', 0.69)\n",
      "('F1-Score: ', 0.79)"
     ]
    }
   ],
   "source": [
    "get_metrics(results_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest performed a bit better than the decision tree! f1 score of 0.79 is actually quite good. It seems that our features worked quite well at predicting user churn in this format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum it up, we found and engineered a useful set of features, tried a few different models, and ended up with a fairly well performing model with an f1-score of 0.79. A few alternatives were tried, event though we weren't going for the highest performance, more for a proof of concept. The random forest ended up being the highest performing model, which isn't too surprising compared to decision trees and logistic regression.\n",
    "\n",
    "This method has proven to be pretty effective, and can clearly distinguish between churned and non churned users when provided the entire timeframe of data. This could be useful in a production service to provide some sort of promotion or treatment to users that are identified as likely to churn.\n",
    "\n",
    "I think both the hardest part and the most interesting part of this project was identifying and extracting features from the events data. It's much less intuitive than many projects we had in the class, so it provided a nice challenge. I would say my main goal for this project was to learn the basics of PySpark, and I think I accomplished that nicely. I have a few other interesting ideas that I didn't have time to investigate in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I found a lot of interesting similarites to the recommendation engines section of the nanodegree even though it wasn't implemented in the same way. A really interesting improvement to this project could be to approach the problem as a timerange problem rather than a random split problem - training on a few weeks of data and testing to see if you can predict the users who churn in the following few weeks. This would be a much more realistic way to apply the model to how we'd like to use it in the real world. It does present a bunch of additional challenges and might require some custom algorithms/evaluators which makes it a more longer term project.\n",
    "\n",
    "Another obvious extension would be to look for instances of `Submit Downgrade` instead of the cancellation events. This would be tracking users who are going to downgrade from paid to free. It would require a different set of features, likely more difficult ones since it would be required to separate different user periods by level. It also would benefit to a similar approach mentioned above, combining the two would be very interesting.\n",
    "\n",
    "That about wraps my project, thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
